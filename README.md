Introduction

This project implements a Vision Transformer (ViT) classifier using TensorFlow and Keras. The model is trained on a subset of the CIFAR-10 dataset and demonstrates the application of transformer architectures to image classification tasks.

Features

Vision Transformer (ViT) implementation
Data augmentation for training
Multi-head self-attention mechanism
MLP head for final classification
Training with AdamW optimizer
Evaluation and prediction utilities

Prerequisites

Python 3.7+
TensorFlow 2.4+
TensorFlow Addons
NumPy
Matplotlib
